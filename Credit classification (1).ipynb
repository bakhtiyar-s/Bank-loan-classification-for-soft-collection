{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/hmeq-data/hmeq.csv')\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include ='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = pd.DataFrame()\nmissing['Total missing'] = data.isnull().sum()\nmissing['%'] = data.isnull().sum()/len(data.index)*100\nmissing['%'] = missing['%'].round(1)\nmissing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(method='ffill', inplace=True)\ndata.fillna(method='bfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data['BAD']).set_title(\"Target Variable Distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.set_style(\"whitegrid\")\nsns.countplot(data['REASON']).set_title(\"Reason Variable Distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.set_style(\"whitegrid\")\nsns.countplot(data['JOB']).set_title(\"Job Variable Distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = [x for x in data.columns if data[x].dtype in ['int', 'float']]\nnum = data[numerical_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.set_style(\"whitegrid\")\n\nfig, axes = plt.subplots(ncols=2, nrows=5)\n\n# for i , k in zip(numerical_cols[1:], range(1,len(numerical_cols)-1)):\n#     plt.figure(figsize=(5,5))\n#     ax = fig.add_subplot(5,5,k)\n#     sns.distplot(data[i], kde=False,bins=30, hist_kws={\"histtype\": 'bar', \"linewidth\": 1, \"alpha\": 0.5}).set_title(\"{col_name} Variable Distribution\".format(col_name = i))\n    \n# for i, ax in zip(numerical_cols[1:], axes.flat):\n#     plt.figure(figsize=(10,10))\n#     sns.distplot(data[i], kde=False, ax=ax, bins=30, hist_kws={\"histtype\": 'bar', \"linewidth\": 1, \"alpha\": 0.5}).set_title(\"{col_name} Variable Distribution\".format(col_name = i))\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE,ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['BAD']\nX = data.drop(['BAD'], axis=1)\nX = pd.get_dummies(X)\nsmo = SMOTE(random_state=0)\nX_resampled, y_resampled = smo.fit_resample(X, y)\nsns.countplot(y_resampled)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smo = SMOTE(random_state=0)\nX_resampled, y_resampled = smo.fit_resample(X, y)\nsns.countplot(y_resampled)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_resampled, y_resampled, test_size=0.2,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom imblearn.over_sampling import SMOTE,ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedKFold\nfrom collections import Counter\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spot Check Algorithms\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression(random_state=0)))\nmodels.append(('Bagging', BaggingClassifier(random_state=0)))\nmodels.append(('Random Forest', RandomForestClassifier(random_state=0)))\nmodels.append(('AdaBoost', AdaBoostClassifier(random_state=0)))\nmodels.append(('GBM', GradientBoostingClassifier(random_state=0)))\nmodels.append(('XGB', XGBClassifier(random_state=0)))\nresults_v = []\nnames = []\nscore = []\nskf = StratifiedKFold(n_splits=5)\nfor (name, model) in models:\n    param_grid = {}\n    my_model = GridSearchCV(model,param_grid,cv=skf)\n    my_model.fit(X_train, y_train)\n    predictions_v = my_model.predict(X_valid)\n    accuracy_valid = accuracy_score(y_valid, predictions_v) \n    results_v.append(accuracy_valid)\n    names.append(name)\n    f_dict = {'model': name,'accuracy_valid': accuracy_valid}\n\n    # Plot non-normalized confusion matrix\n    plot_confusion_matrix(my_model, X_valid, y_valid, values_format = 'd', cmap=plt.cm.Blues, xticks_rotation = 'horizontal').ax_.set_title(str(name)+' Model Confusion Matrix')\n    plt.grid(False)\n    score.append(f_dict)\n\nplt.show()   \n\nscore = pd.DataFrame(score, columns = ['model', 'accuracy_valid'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}